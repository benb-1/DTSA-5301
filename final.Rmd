---
title: "DTSA-5301 Final Project"
output: html_document
date: "2022-10-01"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(lubridate)

url_head = "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_"

url_tails = c("confirmed_US.csv", "confirmed_global.csv", "deaths_US.csv", "deaths_global.csv")

urls = str_c(url_head, url_tails)
```
## ---  
We have set the URLs properly, now we must read the data as a csv and import it to our workspace.
  
```{r import}
cases_us_csv = read_csv(urls[1], show_col_types = FALSE)
cases_global_csv = read_csv(urls[2], show_col_types = FALSE)
deaths_us_csv = read_csv(urls[3], show_col_types = FALSE)
deaths_global_csv = read_csv(urls[4], show_col_types = FALSE)
```
  
## ---
Now that our data is loaded, let’s clean it.
Most of the information from the csv is not necessary, so we’ll remove most columns, and pivot the data so that, for every area and date, the cases and deaths are recorded in a new row (tidy form).
At the end, we’ll want a data frame where each row contains the recorded cumulative deaths and cases for a given country/state on a given day.  
```{r tidy}
deaths_global = pivot_longer(deaths_global_csv, cols = -c(`Province/State`, `Country/Region`, Lat, Long), names_to="date", values_to = "deaths") %>% select(-c(Lat, Long))
deaths_global$date = mdy(deaths_global$date)

cases_global = pivot_longer(cases_global_csv, cols = -c(`Province/State`, `Country/Region`, Lat, Long), names_to="date", values_to = "cases") %>% select(-c(Lat, Long))
cases_global$date = mdy(cases_global$date)
global = full_join(deaths_global, cases_global)

deaths_us = deaths_us_csv %>% select(-c(Population, Lat, Long_, UID, iso2, iso3, code3, FIPS, Country_Region, Combined_Key))
deaths_us = pivot_longer(deaths_us, cols = -c(`Province_State`, Admin2), names_to="date", values_to = "deaths")
deaths_us$date = mdy(deaths_us$date)

cases_us = cases_us_csv %>% select(-c(Lat, Long_, UID, iso2, iso3, code3, FIPS, Country_Region, Combined_Key))
cases_us = pivot_longer(cases_us, cols = -c(`Province_State`, Admin2), names_to="date", values_to = "cases")
cases_us$date = mdy(cases_us$date)

```

```{r tidy pt 2}
us = full_join(cases_us, deaths_us)
us = us %>%
  group_by(`Province_State`, date) %>%
  summarize(cases=sum(cases), deaths=sum(deaths)) %>%
  select(`Province_State`, date, cases, deaths) %>%
  ungroup
colnames(us) = c("state", "date", "cases", "deaths")

global = full_join(cases_global, deaths_global)
global = global %>%
  group_by(`Country/Region`, date) %>%
  summarize(cases=sum(cases), deaths=sum(deaths)) %>%
  select(`Country/Region`, date, cases, deaths) %>%
  ungroup
colnames(global) = c("country", "date", "cases", "deaths")
```
  
## ---
Now that we have our cleaned and tidied data, let’s see a plot of cases and deaths by date, for the first few “States”
```{r cases & death plot}
head(unique(us$state))
g = ggplot()
for(s in head(unique(us$state))) {
  g = g + geom_line(data=filter(us, state==s)[1:365,], aes(x=date, y=log(deaths)), color="black") + 
          geom_line(data=filter(us, state==s)[1:365,], aes(x=date, y=log(cases)), color="red") +
          ggtitle("Cases (red) and Deaths (black), by Date", subtitle="Logarithmic plot, selected US states (1 year)")
}
g = g + ylab("log(Cumulative Cases and Deaths by day)"); g
```
  
## ---
The graph shows an obvious correlation between cases and deaths. This is a good sanity check, as we would certainly expect this.
Now let’s try to fit a model that predicts deaths given cases.

## Blue lines: Model's prediction
## Black lines: Observed data
```{r modeling}
model = lm(data=us, deaths~poly(cases, 4))

par(mfrow=c(2, 2))

for(s in c("California", "Colorado", "Florida", "Alaska")) {
  ca = filter(us, state==s)
  print(ggplot(ca, aes(x=date, y=deaths)) + 
    geom_line() + 
    geom_line(aes(x=date, y=predict(model, new=data.frame(cases=cases))), color="blue") +
    ggtitle("Cumulative deaths by date", subtitle=str_c(s, " observed (black) and US-based model predictions (blue)")))
  }
```
  
## ---
Here, we’ve fitted a model that maps cases to deaths using the US data.
I’ve plotted the observed vs. predicted death values for four states: Colorado, California, Florida, and Alaska We can see that, for the States of California and Florida, not differing by much or for too long.
For Colorado, it also matches pretty well, but becomes very positively biased in 2022.
For Alaska, the fit is much worse, matching some trends but overall very positively biased.

This model and its predictions are a good example of the dangers of both: - Using a model on the same training data which generated it, and - Using a model on on data that does not behave the same way as the training data.

Let’s see how the model holds up internationally.
```{r international modeling}
set.seed(1)
sample_countries = sample(unique(global$country), 8)

for(c in sample_countries) {
  print(ggplot(filter(global, country==c), aes(x=date, y=deaths)) + 
    geom_line() + 
    geom_line(aes(x=date, y=predict(model, new=data.frame(cases=cases))), color="blue") +
    ggtitle("Cumulative deaths by date", subtitle=str_c(c, " observed (black) and US-based model predictions (blue)")))
}
```
  
## ---
These graphs show our US-data trained model trying to predict death data for non-US countries.
As you can see, there are some areas where the prediction follows the observed data, but overall the model fails miserably for most cases.

This is a good bit of exploration because it raises questions we could investigate further. The model can fail by being biased and by incorrectly predicting the trend of the data.

For countries like Djibouti and South Sudan, the model seems to capture trends in the data, but is biased way to high. Meanwhile, for countries like Germany and Bahrain, there are sections where the data and the model diverge, suddenly and wildly.

Perhaps Djibouti and South Sudan have under-reported death numbers relative to the US reporting. If cases are still being recorded, the model would predict deaths that do not appear in the data.

And maybe Germany and/or Bahrain had a similar case pattern as the US, but by early 2022, had managed to reduce the fatality rate. Then, cases could go up, driving the model up, while the actual observed deaths fails to follow the model’s predictions. If true, this would explain the sudden large deviation between the data and model for Germany.
  
  
## Biases
The potential sources of bias for datasets like this are numerous and often significant.
One likely reason for the failure of the model to fit much new data would be biases in collection. If cases and/or deaths are not recorded perfectly, that will skew our analysis. The perfection of that data collection depends on the local healthcare situation, culture, and reporting infrastructure, which are likely to vary between different countries.

I too, probably have biases affecting the validity of this analysis. I fitted my model based on aggregate US data since that’s the Covid data I’m most familiar with. Maybe another country would have been a better ‘model’ country, one whose Covid data would better fit other countries on average.
  
  
## Conclusion
I have downloaded and parsed COVID-19 data from Johns Hopkins’ github site. I used aggregate US Covid data to train a model to predict Covid deaths based on Covid cases in a State or Country.
It was seen that this model performs well for high-population US States, likely since those regions contributed the most to the model. When the model was used to predict some other States, problems arose, and the model failed significantly when used to predict other countries’ Covid deaths.
When the model failed, it failed in different ways for different countries. This analysis would provide a good springboard from which to investigate other questions, like what factors in a country affect its Covid data, and how do these factors differ by country.
```{r session info}
sessionInfo()
```

